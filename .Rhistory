rep(0,3)
binsize = 10
max = 27
nbins = ceiling(max/binsize)
nbins
as.list(1:nbins)
result = as.list(1:nbins)
result[1]
result[1] = 1:10
result[[1]] = 1:10
result
sent140[result[[1]],]
for(i in 1:nbins){
nbins[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
1:nbins
for(i in 1:nbins){
result[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
result
for(i in 1:(nbins-1)){
result[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
result[[nbins]] = ((binsize*(nbins-1)+1):max))
result[[nbins]] = ((binsize*(nbins-1)+1):max)
result
binsize = 12
max = 27
nbins = ceiling(max/binsize)
result = as.list(1:nbins)
for(i in 1:(nbins-1)){
result[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
result[[nbins]] = ((binsize*(nbins-1)+1):max)
result
bins = function(binsize, max){
nbins = ceiling(max/binsize)
result = as.list(1:nbins)
for(i in 1:(nbins-1)){
result[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
result[[nbins]] = ((binsize*(nbins-1)+1):max)
return(result)
}
bins(10,101)
bins(7,54)
bin.maker = function(binsize, max){
nbins = ceiling(max/binsize)
result = as.list(1:nbins)
for(i in 1:(nbins-1)){
result[[i]]=((binsize*(i-1)+1):(binsize*(i)))
}
result[[nbins]] = ((binsize*(nbins-1)+1):max)
return(result)
}
rm(n)
rm(nn)
rm(max)
rm(nbins)
rm(x)
rm(xg)
rm(g)
rm(i)
rm(a)
rm9ans
rm(ans)
rm(binsize)
rm(column_names)
rm(blah)
rm(bins)
experimental.classify.polarity.machine = function(documents, model = rf.model, chunk.size){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in length(chunks)){
print(chunks[[i]])
}
term.freq <- t(apply(t(documents), 2,    #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = paste("X", 1:1024, sep = "")
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
return(pred.sentiment[,1])
}
experimental.classify.polarity.machine = function(documents, chunk.size, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in length(chunks)){
print(chunks[[i]])
}
term.freq <- t(apply(t(documents), 2,    #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = paste("X", 1:1024, sep = "")
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
return(pred.sentiment[,1])
}
experimental.classify.polarity.machine(sent140$clean, chunk.size = 100)
experimental.classify.polarity.machine = function(documents, chunk.size, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
print(chunks[[i]])
}
term.freq <- t(apply(t(documents), 2,    #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = paste("X", 1:1024, sep = "")
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
return(pred.sentiment[,1])
}
experimental.classify.polarity.machine(sent140$clean, chunk.size = 100)
experimental.classify.polarity.machine = function(documents, chunk.size, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
term.freq <- t(apply(t(documents[chunks[[i]]]), 2,    #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
print(pred.sentiment[,1])
}
return(pred.sentiment[,1])
}
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text)
Sys.time()-a
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text, chunk.size = 100)
Sys.time()-a
result = list()
result = c(result, pred.sentiment[,1])
result
result = NULL
result = c(result, pred.sentiment[,1])
result
experimental.classify.polarity.machine = function(documents, chunk.size, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
}
return(result)
}
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text, chunk.size = 100)
Sys.time()-a
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text, chunk.size = 1000)
Sys.time()-a
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text, chunk.size = 300)
Sys.time()-a
a = Sys.time()
ans = experimental.classify.polarity.machine(sent140$text, chunk.size = 30)
Sys.time()-a
print(ans)
a = Sys.time()
sent140$rf.polarity = experimental.classify.polarity.machine(sent140$text, chunk.size = 30)
Sys.time()-a
head(sent140)
sent140
sent140
dim(sent140)
table(sent140$rf.polarity)
classify.polarity.machine = function(documents, chunk.size = 1000, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
}
return(result)
}
classify.polarity.machine = function(documents, chunk.size = 1000, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
print(paste(i*chunk.size, "out of", length(documents), "rows analyzed:", i*100*chunk.size/nrow(x2), "percent complete"))
}
return(result)
}
source("functions.R")
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
load(file = paste(storage.directory, "x1.RData", sep = ""))
dim(x) # x now has 12 columns, 1 more than before
dim(x1) # x now has 12 columns, 1 more than before
x1$rf.polarity = classify.polarity.machine(x1$clean, chunk.size = 5000)
classify.polarity.machine = function(documents, chunk.size = 1000, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
print(paste(i*chunk.size, "out of", length(documents), "rows analyzed:", i*100*chunk.size/length(documents), "percent complete"))
}
return(result)
}
x1 = x1[1:2016,]
x1$rf.polarity = classify.polarity.machine(x1$clean, chunk.size = 5000)
x1$rf.polarity = classify.polarity.machine(x1$clean, chunk.size = 1000)
load(file = paste(storage.directory, "x1.RData", sep = ""))
a = Sys.time()
x1$rf.polarity = classify.polarity.machine(x1$clean, chunk.size = 5000)
# Save x1  and x2 into storage directory
save(x1, file = paste(storage.directory, "x1.RData", sep = ""))
#save(x2, file = paste(storage.directory, "x2.RData", sep = ""))
# write table
write.table(x1, file = paste(storage.directory, "LA2014_with.rf.polarity.csv", sep = ""), row.names = FALSE, sep = ",")
# append table
# write.table(x2, file = paste(storage.directory, "LA2014_with.rf.polarity.csv", sep = ""), col.names = FALSE, append = TRUE)
print(Sys.time() - a)
dim(x2)
dim(x1)
head(x1)
tail(x1)
rm(x1)
load(file = paste(storage.directory, "x2.RData", sep = ""))
load("functions.R")
source("functions.r")
source("functions.R")
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
load(file = paste(storage.directory, "x2.RData", sep = ""))
dim(x2)
head(x2)
tail(x2)
# rf.polarity
a = Sys.time()
x2$rf.polarity = classify.polarity.machine(x2$clean, chunk.size = 5000)
# Save x1  and x2 into storage directory
#save(x1, file = paste(storage.directory, "x1.RData", sep = ""))
save(x2, file = paste(storage.directory, "x2.RData", sep = ""))
# write table
# write.table(x1, file = paste(storage.directory, "LA2014_with.rf.polarity.csv", sep = ""), row.names = FALSE, sep = ",")
# append table
write.table(x2, file = paste(storage.directory, "LA2014_with.rf.polarity.csv", sep = ""), col.names = FALSE, append = TRUE)
print(Sys.time() - a)
2/7
2/6
help(as.numerica)
help(as.numeric)
as.numeric(2/7, length = 2)
numeric(2/7, length = 2)
numeric(length = 2)
numeric(length = 7)
help(float)
pi
pi,3
pi(3)
pi[3]
trunc(2/7, digits = 4)
trunc(2/7, digits = 7)
trunc(10/7, digits = 7)
round(10/7, digits = 7)
round(10/7, digits = 2)
sent140$rf.polarity = classify.polarity.machine(sent140$text, chunk.size = 30)
load(file = paste(storage.directory, "sent140.RData", sep = ""))
sent140$rf.polarity = classify.polarity.machine(sent140$text, chunk.size = 30)
classify.polarity.machine = function(documents, chunk.size = 1000, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
print(paste(i*chunk.size, "out of", length(documents), "rows analyzed:",
round((i-1)*100*chunk.size/length(documents), digits = 1), "percent complete"))
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
}
return(result)
}
sent140$rf.polarity = classify.polarity.machine(sent140$text, chunk.size = 30)
classify.polarity.machine = function(documents, chunk.size = 1000, model = rf.model){
require(plyr)
require(dplyr)
require(randomForest)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[1:1024,]
column.names = paste("X", 1:1024, sep = "")
result = NULL
print("setup complete")
chunks = bin.maker(chunk.size, length(documents))
for(i in 1:length(chunks)){
print(paste((i-1)*chunk.size, "out of", length(documents), "rows analyzed:",
round((i-1)*100*chunk.size/length(documents), digits = 1), "percent complete"))
term.freq <- t(apply(t(documents[chunks[[i]]]), 2, #MAY TAKE TIME!
ndsi.frequencies))
colnames(term.freq) = column.names
pred.sentiment = predict(model, newdata = term.freq, type = "prob")
result = c(result, pred.sentiment[,1])
}
return(result)
}
sent140$rf.polarity = classify.polarity.machine(sent140$text, chunk.size = 30)
rm(x2)
rm(rf.model)
load(file = paste(storage.directory, "LA2014.RData", sep = "")) # load LA2014 into memory as LA2014
# Set date and time to POSIXlt form ----
LA2014$time = as.POSIXlt(paste(paste(LA2014$year, LA2014$month, LA2014$date, sep = "-"), "  ", paste(LA2014$hour, LA2014$minute, LA2014$second, sep = ":"), sep = ""))
LA2014$year = NULL
LA2014$month = NULL
LA2014$date = NULL
LA2014$hour = NULL
LA2014$minute = NULL
LA2014$second = NULL
index = sample(100000, size = nrow(LA2014))
index = sample(nrow(LA2014), size = 100000)
head(index)
LAsample = LA2014[index,]
ggplot(LAsample, aes(AFINN.polarity, rf.polarity)) +
geom_point()
library(ggplot)
library(ggplot2)
ggplot(LAsample, aes(AFINN.polarity, rf.polarity)) +
geom_point()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
scale_y_log10()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
scale_x_log10()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point()
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
LA2014 = LA2014[LA2014$AFINN.polarity > (-30) & LA2014$AFINN.polarity < 30,]
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
index = sample(nrow(LA2014), size = 100000)
LAsample = LA2014[index,]
LAsample = LAsample[LAsample$AFINN.polarity > (-30) & LAsample$AFINN.polarity < 30,]
ggplot(LAsample, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
rm(LAsample)
rm(LA2014)
head(sent140)
sent140Srf.polarity = classify.polarity.machine(sent140$clean, chunk.size = 100)
source("functions.R")
sent140Srf.polarity = classify.polarity.machine(sent140$clean, chunk.size = 100)
sent140$AFINN.polarity = classify.sentiment(sent140$clean)
head(sent140)
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point(color = polarity) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
colnames(sent140)
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point(color = sent140$polarity) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
clas(sent140Srf.polarity)
class(sent140Srf.polarity)
sent140$polarity = as.factor(sent140$polarity)
class(sent140Srf.polarity)
sent140$polarity = as.factor(sent140$polarity)
class(sent140$polarity)
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point(color = sent140$polarity) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point(color = sent140$polarity) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity)) +
geom_point(color = 2) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity, color = sentiment)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity, color = polarity)) +
geom_point() +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity, color = polarity)) +
geom_point(size = 4) +
ggtitle("rf.polarity vs AFINN.polarity") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity, color = polarity)) +
geom_point(size = 1) +
ggtitle("Sent140 Classification") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
ggplot(sent140, aes(rf.polarity, AFINN.polarity, color = polarity)) +
geom_point(size = 2) +
ggtitle("Sent140 Classification") +
xlab("rf.polarity") +
ylab("AFINN.polarity")
rm(sent140)
rm(a)
rm(index)
rm(freq.all)
rm(AFINN_lexicon)
rm(negatios)
rm(sent140Srf.polarity)
rm(negations)
rm(storage.directory)
