dim(phat)
length(phat)
dim(tf.idf)
dim(emoticon.tf.idf)
phat=predict(svm.model,
newdata = emoticon.tf.idf,
type = "raw")  #not sure what the correct type is
load(paste(storage.directory,"emoticon.tf.idf.RData", sep = "")) # load emoticon.tf.idf lexicon into memory as tf.idf
emoticon.tf.idf = (rbind(head(emoticon.tf.idf,50000), tail(emoticon.tf.idf,50000))) #reduce to 100000
emoticon.tf.idf = emoticon.tf.idf[c((nTraining+1):50000,50001:(100000-(nTraining))),] #test data
pred.sentiment=predict(svm.model, newdata = emoticon.tf.idf)
confusionMatrix(pred.sentiment, emoticon.tf.idf$polarity)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 10000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("clean", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
library(cldr)
source(functions.R)
source("functions.R")
x[,"text"] = clean.tweets(x$text)
dim(x)
x = x[nchar(x$text)>2,]
dim(x)
x$language = detectLanguage(x$clean)$detectedLanguage
dim(x)
detectLanguage(x$clean)
detectLanguage("hello world")
detectLanguage(c("hello world", "hola mundo")
)
detectLanguage(c("hello world", "hola mundo"))
class(x$clean)
x[,"text"] = clean.tweets(x$text)
x$language = detectLanguage(x$text)$detectedLanguage
x$isReliable = detectLanguage(x$text)$isReliable
table(x$isReliable, x$language)
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("clean", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("clean", "language")]
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")])
x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language == "Unknown" & x$isReliable == TRUE, c("text", "language")])
x[x$language == "Unknown" & x$isReliable == TRUE, c("text", "language")] #These are all blank tweets
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 100000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x$language = detectLanguage(x$text)$detectedLanguage
x$isReliable = detectLanguage(x$text)$isReliable
table(x$isReliable, x$language)
#non-English Tweets
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x[,"text"] = clean.tweets(x$text)
x = x[nchar(x$text)>2,]
dim(x)
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x$language = detectLanguage(x$text)$detectedLanguage
x$isReliable = detectLanguage(x$text)$isReliable
table(x$isReliable, x$language)
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text")]
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")])
x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")]
x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")])
dim(x[x$language == "Unknown" & x$isReliable == TRUE, c("text", "language")])
x[x$language == "Unknown" & x$isReliable == TRUE, c("text", "language")] #These are all blank tweets
x[x$language != "ENGLISH" & x$isReliable == TRUE $ x$language != "SPANISH", c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE & x$language != "SPANISH", c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE & x$language != "SPANISH", c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE & x$language != "SPANISH", c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE & x$language != "SPANISH", c("language", "text")]
x[x$language != "ENGLISH" & x$isReliable == TRUE &, c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE , c("text", "language")]
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 100000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
colnames(x)
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# clean x
x[,"text"] = clean.tweets(x$text)
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
dim(x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]) #The blank and SPANISH tweets look like they could be removed, but other tweets look pretty English
x[x$language != "ENGLISH" & x$isReliable == TRUE, c("text", "language")]
dim(x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")])
x[x$language == "SPANISH" & x$isReliable == TRUE, c("text", "language")]
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
dim(x)
x = x[nchar(x$text)>2,]
dim(x)
x = x[x$language != "SPANISH" | x$isReliable == FALSE, c("text", "language")]
dim(x)
x[,"AFINN.sentiment"] = classify.sentiment(x$text, lexicon = AFINN_lexicon)
dim(x) # text now has 15 columns, 4 more than before
head(x)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 10000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# clean x
x[,"text"] = clean.tweets(x$text)
# remove empty rows
x = x[nchar(x$text)>2,]
# remove very Spanish-sounding tweets
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
dim(x)
x[,"AFINN.sentiment"] = classify.sentiment(x$text, lexicon = AFINN_lexicon)
#Skip rerunning Wiebe through sentiment2 because it's not as good and will run slower
dim(x) # text now has 15 columns, 4 more than before
x[,c("language", "isReliable")] = c(NULL, NULL)
x$language = NULL
x$isReliable = NULL
dim(x) # text now has 14 columns, 3 more than before
storage.directory = "~/Desktop/Huang Research/Rsentiment/"
write.table(x, file = paste(storage.directory, "LA2014.lexicon.csv", sep = ""), col.names = FALSE, append = TRUE)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 10000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# clean x
x[,"text"] = clean.tweets(x$text)
# remove empty rows
x = x[nchar(x$text)>2,]
# remove very Spanish-sounding tweets
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
x$language = NULL
x$isReliable = NULL
# AFINN sentiment
x[,"AFINN.sentiment"] = classify.sentiment(x$text, lexicon = AFINN_lexicon)
#Skip rerunning Wiebe through sentiment2 because it's not as good and will run slower
dim(x) # text now has 12 columns, 1 more than before
head(x)
# Random Forest Sentiment -- coming soon!
# write table
# write.table(x, file = "~/Desktop/Huang Research/Rsentiment/latweets.sentiment2.csv", row.names = FALSE, sep = ",")
# append table
write.table(x, file = paste(storage.directory, "LA2014.csv", sep = ""), col.names = FALSE, append = TRUE)
rm(x)
print(Sys.time() - a)
source("functions.R")
a = Sys.time()
print(a)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 10000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# clean x
x[,"text"] = clean.tweets(x$text)
# remove empty rows
x = x[nchar(x$text)>2,]
# remove very Spanish-sounding tweets
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
x$language = NULL
x$isReliable = NULL
# AFINN sentiment
x[,"AFINN.polarity"] = classify.sentiment(x$text, lexicon = AFINN_lexicon)
#Skip rerunning Wiebe through sentiment2 because it's not as good and will run slower
dim(x) # text now has 12 columns, 1 more than before
head(x)
# Random Forest Sentiment -- coming soon!
# write table
write.table(x, file = paste(storage.directory, "LA2014.csv", sep = ""), row.names = FALSE, sep = ",")
rm(x)
print(Sys.time() - a)
y = read.csv(file = paste(storage.directory, "LA2014.csv", sep = ""), skip = 0, nrows = 2000, header = TRUE,
colClasses = c("character", "character", "character", "numeric", "numeric", "integer",
"integer", "integer", "integer", "integer", "integer", "integer", "integer"))
y = read.csv(file = paste(storage.directory, "LA2014.csv", sep = ""), skip = 0, nrows = 2000, header = TRUE,
colClasses = c("character", "character", "character", "numeric", "numeric", "integer",
"integer", "integer", "integer", "integer", "integer", "integer"))
set.seed(100)
idx = sample(nrow(y), 100)
y.sample = y[idx,c("text", "username", "AFINN.polarity")]
dim(y) #8859604 rows
range(y$AFINN.polarity) # -135  88
mean(y$AFINN.polarity) # 0.4408979
hist(y$AFINN.polarity) # try to change y-axis to log scale. Maybe use ggplot
quantile(y$AFINN.polarity, c(0, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 1))
#look at some of the extreme entries
hist(y$AFINN.polarity[y$AFINN.polarity > 25 | y$AFINN.polarity < (-25)]) #tails of AFINN.polarity
# VERY HAPPY:
x_2 = y[y$AFINN.polarity>50, c("text", "AFINN.polarity")] #again, lots of repeated words. Fewer negation problems.
happy = unique(rbind(x_1, x_2))
w_2 = y[y$AFINN.polarity<(-75), c("text", "Wiebe.polarity", "AFINN.polarity")] #again, lots of repeated words. Fewer negation problems.
w_2 = y[y$AFINN.polarity<(-75), c("text", "AFINN.polarity")] #again, lots of repeated words. Fewer negation problems.
y[y$AFINN.polarity>50, c("text", "AFINN.polarity")] #again, lots of repeated words. Fewer negation problems.
y[y$AFINN.polarity<(-75), c("text", "AFINN.polarity")] #again, lots of repeated words. Fewer negation problems.
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 94000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# remove very Spanish-sounding tweets
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
x$language = NULL
x$isReliable = NULL
dim(x)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 940000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
# remove very Spanish-sounding tweets
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
x$language = NULL
x$isReliable = NULL
dim(x)
rm(w_2)
rm(x)
rm(x_2)
rm(y)
rm(y.sample)
rm(a)
rm(idx)
rm(nTraining)
rm(emoticon.tf.idf)
hist(y$AFINN.polarity) # try to change y-axis to log scale. Maybe use ggplot
y = read.csv(file = paste(storage.directory, "LA2014.csv", sep = ""), skip = 0, nrows = 2000, header = TRUE,
colClasses = c("character", "character", "character", "numeric", "numeric", "integer",
"integer", "integer", "integer", "integer", "integer", "integer"))
hist(y$AFINN.polarity) # try to change y-axis to log scale. Maybe use ggplot
hist(y$AFINN.polarity, log = "y")
help(hist)
a = Sys.time()
print(a)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 10000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
rm(x)
rm(y)
rm(negations)
rm(phat)
rm(svm.model)
a = Sys.time()
print(a)
x = read.csv(file = "~/Desktop/Huang Research/Rsentiment/ComTweetsLA.csv", skip = 1, nrows = 9400000, header = FALSE, colClasses =
c("character", "character", "character", "numeric", "numeric", "integer", "integer", "integer", "integer", "integer", "integer"))
colnames(x) = c("text","username","tweet_id","lat","long","year","month","date","hour","minute","second")
x = x[!is.na(x$date),]
# Set date and time
x$time = as.POSIXlt(paste(paste(x$year, x$month, x$date, sep = "-"), "  ", paste(x$hour, x$minute, x$second, sep = ":"), sep = ""))
x$year = NULL
x$month = NULL
x$date = NULL
x$hour = NULL
x$minute = NULL
x$second = NULL
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
library(cldr) # for detecting tweet language
x[,c("language", "isReliable")] = detectLanguage(x$text)[c("detectedLanguage", "isReliable")]
x = x[x$language != "SPANISH" | x$isReliable == FALSE,]
9383334-9227873
x$language = NULL
x$isReliable = NULL
x = x[nchar(x$text)>2,]
save(x, paste(storage.directory, "x.RData", sep = "")) # save x into storage directory
save(x, file = paste(storage.directory, "x.RData", sep = "")) # save x into storage directory
rm(x)
a = Sys.time()
print(a)
load(file = paste(storage.directory, "x.RData", sep = ""))
rm(x)
rm(pred.sentiment)
rm(a)
rm(rand.which.max)
rm(confmatrix)
source("functions.R")
load("~/Desktop/Huang Research/Rsentiment/emoticon.RData") # load train/emoticon into memory as emoticon
table(emoticon$polarity)
head(word.freq(head(emoticon$clean,1000)), 100) # create word frequency data frame for first 1000 tweets
word.freq.pos = word.freq(emoticon$clean[emoticon$polarity == 1],
sparsity=0.9999) #terms must occur in at least 1 out of 1000 tweets
source("functions.R")
word.freq.pos = word.freq(emoticon$clean[emoticon$polarity == 1],
sparsity=0.9999) #terms must occur in at least 1 out of 1000 tweets
word.freq.neg = word.freq(emoticon$clean[emoticon$polarity == 0],
sparsity=0.9999)
dim(word.freq.pos)
dim(word.freq.neg)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
#Merge by word
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
#Set NA's to 0
freq.all$freq.x[is.na(freq.all$freq.x)] = 0
freq.all$freq.y[is.na(freq.all$freq.y)] = 0
#Differences between Positive and Negative Frequencies
freq.all$diff = abs(freq.all$freq.x - freq.all$freq.y)
head(freq.all[order(-freq.all$diff), ],100) #this is somewhat puzzling
#Smoothing term
alpha <- 2^7
#NDSI
freq.all$ndsi = abs(freq.all$freq.x -
freq.all$freq.y)/(freq.all$freq.x +
freq.all$freq.y +
2 * alpha)
#Sorting by NDSI
freq.all = freq.all[order(-freq.all$ndsi), ]
head(freq.all, 100)
#Convert word to a string
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
head(freq.all$word,100)
freq.all = freq.all[freq.all$ndsi>0,] # restrict to words with a nonzero ndsi score.
freq.all$word = as.character(freq.all$word)
dim(freq.all)
head(freq.all)
freq.all = freq.all[freq.all$ndsi>0.05,]
dim(freq.all)
freq.all = freq.all[freq.all$ndsi>0.05,]
dim(freq.all)
rm(word.freq.neg)
rm(word.freq.pos)
a = Sys.time()
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
Sys.time()-a
load(file = paste(storage.directory, "sent140.RData", sep = ""))
a = Sys.time()
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
Sys.time()-a
dim(test)
inv.doc.freq
head(term.freq)
head(freq.all)
head(test)
head(test, 8)
head(freq.all,94)
head(test, 8)
head(freq.all,94)
term.freq
colSums
inv.doc.freq=log(nrow(emoticon)/colSums(sign(term.freq)))
range(inv.doc.freq)
inv.doc.freq[is.infinite(inv.doc.freq)]=0
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
dim(tf.idf)
tf.idf[1:10,1:10]
tf.idf[1:25,1:10]
tf.idf[1:25,1:125]
tf.idf[1:25,1:25]
tf.idf[,1]
tf.idf[,2]
tf.idf[,5]
tf.idf[,6]
tf.idf[,7]
tf.idf[,9]
tf.idf[,100]
tf.idf[,101]
tf.idf[,102]
tf.idf[,103]
tf.idf[,104]
tf.idf[,105]
tf.idf[,106]
tf.idf[,1000]
tf.idf[,1001]
tf.idf[,1002]
tf.idf[,1003]
tf.idf[,1004]
pred.sentiment=predict(rf.model, newdata = tf.idf)
load(file = paste(storage.directory, "rf.model.RData", sep = ""))
pred.sentiment=predict(rf.model, newdata = tf.idf)
colnames(tf.idf)
head(tf.idf)
class(tf.idf)
as.matrix(tf.idf)
as.df(tf.idf)
as.data.frame(tf.idf)
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
dim(tf.idf)
tf.idf = as.data.frame(tf.idf)
colnames(tf.idf)
paste("X", 1:1024)
paste("X", 1:1024, sep = "")
colnames(tf.idf) = paste("X", 1:1024, sep = "")
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
pred.sentiment
test$polarity
confusionMatrix(pred.sentiment,test$polarity)
phat=predict(rf.model,
newdata = tf.idf,
type = "prob")
plot(roc(emoticon.tf.idf$polarity,phat[,2]))
plot(roc(tf.idf$polarity,phat[,2]))
plot(roc(test$polarity,phat[,2]))
colSums(sign(term.freq))
ndsi.frequencies
ndsi.frequencies$word
ndsi.lexicon
rm(freq.all)
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
ndsi.lexicon = freq.all[freq.all$ndsi>0.05,]
dim(ndsi.lexicon)
# Apply freq.all to test data (2 secs for test's 359 rows, but otherwise costly)
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
tf.idf = as.data.frame(tf.idf)
colnames(tf.idf) = paste("X", 1:1024, sep = "") #hacky fix for column names
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
#Accuracy
confusionMatrix(pred.sentiment,test$polarity) # Accuracy is a respectable 68%
# ROC curve
phat=predict(rf.model,
newdata = tf.idf,
type = "prob")
plot(roc(test$polarity,phat[,2])) #Even more respectable 76.65%
head(tf.idf)
rm(tf.idf)
tf.idf = as.data.frame(term.freq)
colnames(tf.idf) = paste("X", 1:1024, sep = "") #hacky fix for column names
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
#Accuracy
confusionMatrix(pred.sentiment,test$polarity) # Accuracy is a respectable 68%
phat=predict(rf.model,
newdata = tf.idf,
type = "prob")
plot(roc(test$polarity,phat[,2])) #Even more respectable 76.65%
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
# More magic here. Need to understand this better
inv.doc.freq=log(nrow(emoticon)/colSums(sign(term.freq)))
range(inv.doc.freq)
inv.doc.freq[is.infinite(inv.doc.freq)]=0
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
# Prediction
tf.idf = as.data.frame(tf.idf)
colnames(tf.idf) = paste("X", 1:1024, sep = "") #hacky fix for column names
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
#Accuracy
confusionMatrix(pred.sentiment,test$polarity) # Accuracy is a respectable 68%
# ROC curve
phat=predict(rf.model,
newdata = tf.idf,
type = "prob")
plot(roc(test$polarity,phat[,2])) #Even more respectable 76.65%
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
Sys.time()-a
rm(freq.all)
a = Sys.time()
term.freq <- t(apply(t(emoticon[,"clean"]), 2,    #TAKES TIME; 10 minutes for 100 000 tweets and 1276 terms
ndsi.frequencies))
Sys.time()-a
freq.all = freq.all[freq.all$ndsi>0.05,]
load(paste(storage.directory,"freq.all.RData", sep = "")) # load freq.all lexicon into memory as freq.all
freq.all = freq.all[freq.all$ndsi>0.05,]
dim(freq.all)
a = Sys.time()
term.freq <- t(apply(t(emoticon[,"clean"]), 2,    #TAKES TIME; 10 minutes for 100 000 tweets and 1276 terms
ndsi.frequencies))
Sys.time()-a
tf.idf = term.freq %*% diag(inv.doc.freq)
save(inv.doc.freq, file = paste(storage.directory, "inv.doc.freq.RData", sep = "")) #save inv.doc freq for classifier
diag(inv.doc.freq)
help(d9ag)
help(diag)
tf.idf = term.freq %*% diag(inv.doc.freq)
dim(term.freq)
term.freq <- t(apply(t(test[,"clean"]), 2,    #TAKES TIME; 10 minute for 100 000 tweets and 1276 terms
ndsi.frequencies))
tf.idf = term.freq %*% diag(inv.doc.freq)
tf.idf = as.data.frame(tf.idf)
colnames(tf.idf) = paste("X", 1:1024, sep = "") #hacky fix for column names
pred.sentiment=predict(rf.model, newdata = as.data.frame(tf.idf))
#Accuracy
confusionMatrix(pred.sentiment,test$polarity) # Accuracy is a respectable 68%
phat=predict(rf.model,
newdata = tf.idf,
type = "prob")
plot(roc(test$polarity,phat[,2])) #Even more respectable 76.65%
load(file = paste(storage.directory, "inv.doc.freq.RData", sep = ""))
help("%*%")
diag(inv.doc.freq)
rm(rf.model)
rm(pred.sentiment)
rm(a)
rm(alpha)
rm(inv.doc.freq)
rm(phat)
rm(term.freq)
rm(freq.all)
rm(emoticon)
rm(ndsi.lexicon)
rm(test)
rm(tf.idf)
