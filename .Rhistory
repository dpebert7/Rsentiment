class(testdata)
head(testdata)
testdata = read.csv(file = "testdata.manual.2009.06.14.csv", header = FALSE, stringsAsFactors = FALSE)
dim(testdata)
colnames(testdata) = c("polarity", "ID", "date", "query", "username", "text") # column names
testdata$polarity = as.factor(testdata$polarity) # set polarity to factor
colnames(testdata) = c("polarity", "ID", "date", "query", "username", "text") # column names
testdata$polarity = as.factor(testdata$polarity) # set polarity to factor
testdata$polarity == c("negative", "neutral", "positive")
testdata = as.data.frame(cbind(testdata$polarity, testdata$text)) #throw away everything exept polarity and text
colnames(testdata) = c("polarity", "text")
class(testdata)
head(testdata)
testdata$polarity
head(testdata, 20)
testdata$polarity == c("negative", "neutral", "positive")
testdata$polarity = c("negative", "neutral", "positive")
testdata$polarity
testdata = read.csv(file = "testdata.manual.2009.06.14.csv", header = FALSE, stringsAsFactors = FALSE)
dim(testdata)
colnames(testdata) = c("polarity", "ID", "date", "query", "username", "text") # column names
testdata$polarity = as.factor(testdata$polarity) # set polarity to factor
testdata = as.data.frame(cbind(testdata$polarity, testdata$text)) #throw away everything exept polarity and text
colnames(testdata) = c("polarity", "text")
classes[testdata$polarity]
classses = c("negative", "neutral", "positive")
classses = c("negative", "neutral", "positive")
classes[1]
classes
classes = c("negative", "neutral", "positive")
classes[testdata$polarity]
testdata$polarity = c("negative", "neutral", "positive")[testdata$polarity]
head(testdata)
head(testdata, 40)
table(testdata$polarity)
testdata$clean = clean.data(testdata$text)
head(testdata, 40)
testdata$AFINN = classify.sentiment(testdata$clean)
head(testdata[c("polarity, AFINN, clean")])
head(testdata[c("polarity", "AFINN", "clean")])
testdata$pred = NA
testdata$pred
if(testdata$pred > 0){testdata$pred = "positive"}
class(testdata$AFINN)
if(testdata$pred > 0){testdata$AFINN = "positive"}
if(testdata$AFINN > 0){testdata$pred = "positive"}
testdata$AFINN
testdata$pred
testdata$pred = NA
testdata$pred
sign(3)
sign(-10)
sign(0)
testdata$pred = sign(testdata$AFINN)
testdata$pred
testdata$pred = sign(testdata$AFINN)
testdata$pred = c("negative", "neutral", "positive")[testdata$pred]
testdata$pred = as.factor(sign(testdata$AFINN))
testdata$pred = c("negative", "neutral", "positive")[testdata$pred]
testdata$pred
confmatrix(testdata$pred, testdata$polarity)
caret
library(caret)
install.packages("caret")
library(caret)
confusionMatrix(testdata$AFINN, testdata$pred)
testdata$AFINN
confusionMatrix(testdata$sentiment, testdata$pred)
testdata$sentiment
confusionMatrix(testdata$polarity, testdata$pred)
testdata$Wiebe = classify.sentiment(testdata$clean, lexicon = Wiebe_lexicon)
testdata$predAFINN = as.factor(sign(testdata$AFINN))
testdata$predWiebe = as.factor(sign(testdata$Wiebe))
testdata$pred = c("negative", "neutral", "positive")[testdata$predAFINN]
testdata$pred = c("negative", "neutral", "positive")[testdata$predWiebe]
confusionMatrix(testdata$polarity, testdata$predWiebe)
testdata$predWiebe
testdata$pred = c("negative", "neutral", "positive")[testdata$predWiebe]
confusionMatrix(testdata$polarity, testdata$predWiebe)
testdata$predWiebe = as.factor(sign(testdata$Wiebe))
testdata$pred = c("negative", "neutral", "positive")[testdata$predWiebe]
testdata$predAFINN = c("negative", "neutral", "positive")[testdata$predAFINN]
testdata$predWiebe = c("negative", "neutral", "positive")[testdata$predWiebe]
confusionMatrix(testdata$polarity, testdata$pred)
confusionMatrix(testdata$polarity, testdata$predAFINN)
confusionMatrix(testdata$polarity, testdata$predWiebe)
confusionMatrix(testdata$polarity, testdata$predAFINN)
dim(testdata)
table(testdata$polarity)
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[1:3000,c("text", "polarity")]),sad[1:3000,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
term.freq <- t(apply(t(semisuper$clean), 2,
AFINN_lexicon.frequencies))
source("functions.R") #get cleaning function, AFINN_lexicon
term.freq <- t(apply(t(semisuper$clean), 2,
AFINN_lexicon.frequencies))
library(stringr) #library for str_count function
library(e1071) # for naive bayes model
library(ggplot2) #for graphs
library(caret) #for confusionMatrix
library(pROC) #ROC curves
library(randomForest)
term.freq <- t(apply(t(semisuper$clean), 2,
AFINN_lexicon.frequencies))
a = Sys.time()
Sys.time()-a
a = Sys.time()
term.freq <- t(apply(t(semisuper$clean), 2,
AFINN_lexicon.frequencies))
Sys.time()-a
dim(term.freq)
semisuper$AFINN.rating = as.vector(term.freq %*% AFINN_lexicon$score)
semisuper$clean[20]
AFINN_lexicon[AFINN_lexicon$word == "welcome",]
AFINN_lexicon$word[2420]
term.freq[20,2420]  # the word "welcome" occurs one time in the 20th tweet. Its corresponding AFINN score is +2
set.seed(945)
train = sample(1:nrow(semisuper), 0.7*nrow(semisuper))
semisuper$polarity=as.factor(semisuper$polarity)
nb.model=naiveBayes(polarity~AFINN.rating,
data=semisuper[train,])
ggplot(semisuper[train,],
aes(AFINN.rating, fill = as.factor(polarity))) +
geom_density(alpha = .2)
pred.polarity=predict(nb.model, newdata=semisuper[-train,])
confusionMatrix(pred.polarity,semisuper[-train,]$polarity)
colnames(semisuper)
pred.polarity=predict(nb.model, newdata=semisuper[-train,])
semisuper[-train,]$clean
source("functions.R") #get cleaning function, AFINN_lexicon
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[1:3000,c("text", "polarity")]),sad[1:3000,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
a = Sys.time()
term.freq <- t(apply(t(semisuper$clean), 2,
AFINN_lexicon.frequencies))
Sys.time()-a
dim(term.freq)
semisuper$AFINN.rating = as.vector(term.freq %*% AFINN_lexicon$score)
set.seed(945)
train = sample(1:nrow(semisuper), 0.7*nrow(semisuper))
#Naive Bayes Model
semisuper$polarity=as.factor(semisuper$polarity)
nb.model=naiveBayes(polarity~AFINN.rating,
data=semisuper[train,])
#plot reveals a lot of overlap. This doesn't look like it will be a good classifier
ggplot(semisuper[train,],
aes(AFINN.rating, fill = as.factor(polarity))) +
geom_density(alpha = .2)
pred.polarity=predict(nb.model, newdata=semisuper[-train,])
pred.polarity=predict(nb.model, newdata=semisuper[-train,])
semisuper[-train,]$AFINN.rating
hist(semisuper[-train,]$AFINN.rating)
pred.polarity=predict(nb.model, newdata=semisuper[-train,])
phat=predict(nb.model,
newdata=semisuper[-train,],
type="raw")
rf.semisuper=data.frame(polarity=semisuper$polarity,term.freq)
rf.model=randomForest(polarity~.,data=rf.semisuper[train,])
pred.polarity=predict(rf.model,
newdata=rf.semisuper[-train,])
confusionMatrix(pred.polarity,semisuper$polarity[-train])
phat=predict(rf.model,
newdata=rf.semisuper[-train,],
type="prob")
plot(roc(semisuper$polarity[-train],phat[,2]))
semisuper = rbind(as.data.frame(happy[1:100,c("text", "polarity")]),sad[1:100,c("text", "polarity")])
source("functions.R") #get cleaning function, AFINN_lexicon
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[1:100,c("text", "polarity")]),sad[1:100,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
table(AFINN_lexicon$word)
table(AFINN_lexicon$score)
AFINN_lexicon[score == 5]
AFINN_lexicon[AFINN_lexicon$score == 5,]
AFINN_lexicon[AFINN_lexicon$score == -55,]
AFINN_lexicon[AFINN_lexicon$score == -5,]
AFINN_lexicon[AFINN_lexicon$score == -4,]
AFINN_lexicon[AFINN_lexicon$score == -3,]
library(stringr) #library for str_count function
library(e1071) # for naive bayes model
library(ggplot2) #for graphs
library(caret) #for confusionMatrix
library(pROC) #ROC curves
library(randomForest)
library(tm) # for building term frequency matrix from corpus
source("functions.R") #get cleaning function, AFINN_lexicon
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[,c("text", "polarity")]),sad[,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
semisuper = rbind(as.data.frame(happy[1:100,c("text", "polarity")]),sad[1:100,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
set.seed(945)
train = sample(1:nrow(semisuper), 0.7*nrow(semisuper))
#Naive Bayes Model
semisuper$polarity=as.factor(semisuper$polarity)
nb.model=naiveBayes(polarity~AFINN.rating,
data=semisuper[train,])
semisuper$polarity=as.factor(semisuper$polarity)
rf.semisuper=data.frame(polarity=semisuper$polarity,tf.idf)
word.freq <- function(document.vector, sparsity = .99){
# construct corpus
temp.corpus <- Corpus(VectorSource(document.vector))
# construct tf matrix and remove sparse terms
temp.tf <- DocumentTermMatrix(temp.corpus,
control = list(stopwords = stopwords('english'),
removeNumbers = T))
temp.tf <- removeSparseTerms(temp.tf, sparsity)
temp.tf <- as.matrix(temp.tf)
# construct word frequency df
freq.df <- colSums(temp.tf)
freq.df <- data.frame(word = names(freq.df), freq = freq.df)
rownames(freq.df) <- NULL
return(freq.df)
}
head(word.freq(semisuper$clean), 100)
train.data=semisuper[train,]
word.freq.pos = word.freq(train.data$clean[train.data$polarity == 1],
sparsity=0.999)
word.freq.neg = word.freq(train.data$clean[train.data$polarity == -1],
sparsity=0.999)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
#Merge by word
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
#Set NA's to 0
freq.all$freq.x[is.na(freq.all$freq.x)] = 0
freq.all$freq.y[is.na(freq.all$freq.y)] = 0
#Differences between Positive and Negative Frequencies
freq.all$diff = abs(freq.all$freq.x - freq.all$freq.y)
head(freq.all[order(-freq.all$diff), ])
#Smoothing term
alpha <- 2^7
#NDSI
freq.all$ndsi = abs(freq.all$freq.x -
freq.all$freq.y)/(freq.all$freq.x +
freq.all$freq.y +
2 * alpha)
#Sorting by NDSI
freq.all = freq.all[order(-freq.all$ndsi), ]
head(freq.all, 100)
#Convert word to a string
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
head(freq.all$word)
# Term Frequencies and tfidf with NDSI ----
#AFINN Frequency Function (now used with ndsi lexicon)
freq.all$word = as.character(freq.all$word)
library(stringr)
ndsi.frequencies=function(x){
str_count(x,freq.all$word[1:1024])
}
#Term Frequencies (Takes about two minutes to run)
term.freq <- t(apply(t(semisuper$clean), 2,
ndsi.frequencies))
inv.doc.freq=log(nrow(semisuper)/colSums(sign(term.freq)))
range(inv.doc.freq)
inv.doc.freq[is.infinite(inv.doc.freq)]=0
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
head(tf.idf)
train.data=semisuper[train,]
dim(train.data)
word.freq.pos = word.freq(train.data$clean[train.data$polarity == 1],
sparsity=0.999)
word.freq.neg = word.freq(train.data$clean[train.data$polarity == -1],
sparsity=0.999)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
#Merge by word
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
freq.all$freq.x[is.na(freq.all$freq.x)] = 0
freq.all$freq.y[is.na(freq.all$freq.y)] = 0
freq.all$diff = abs(freq.all$freq.x - freq.all$freq.y)
head(freq.all[order(-freq.all$diff), ])
alpha <- 2^7
freq.all$ndsi = abs(freq.all$freq.x -
freq.all$freq.y)/(freq.all$freq.x +
freq.all$freq.y +
2 * alpha)
head(freq.all)
)
head(freq.all)
head(freq.all[order(-freq.all$diff), ])
alpha <- 2^7
head(freq.all, 100)
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
library(stringr)
ndsi.frequencies=function(x){
str_count(x,freq.all$word[1:1024])
}
term.freq <- t(apply(t(semisuper$clean), 2,
ndsi.frequencies))
inv.doc.freq=log(nrow(semisuper)/colSums(sign(term.freq)))
range(inv.doc.freq)
semisuper = rbind(as.data.frame(happy[1:1000,c("text", "polarity")]),sad[1:1000,c("text", "polarity")])
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[1:1000,c("text", "polarity")]),sad[1:1000,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
#70% training data ----
set.seed(945)
train = sample(1:nrow(semisuper), 0.7*nrow(semisuper))
word.freq <- function(document.vector, sparsity = .99){
head(word.freq(semisuper$clean), 100)
train.data=semisuper[train,]
word.freq.pos = word.freq(train.data$clean[train.data$polarity == 1],
sparsity=0.999)
word.freq.neg = word.freq(train.data$clean[train.data$polarity == -1],
sparsity=0.999)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
#Merge by word
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
)
head(word.freq(semisuper$clean), 100)
train.data=semisuper[train,]
word.freq.pos = word.freq(train.data$clean[train.data$polarity == 1],
sparsity=0.999)
word.freq.neg = word.freq(train.data$clean[train.data$polarity == -1],
sparsity=0.999)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
#Merge by word
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
#Set NA's to 0
freq.all$freq.x[is.na(freq.all$freq.x)] = 0
freq.all$freq.y[is.na(freq.all$freq.y)] = 0
#Differences between Positive and Negative Frequencies
freq.all$diff = abs(freq.all$freq.x - freq.all$freq.y)
head(freq.all[order(-freq.all$diff), ])
#Smoothing term
alpha <- 2^7
#NDSI
freq.all$ndsi = abs(freq.all$freq.x -
freq.all$freq.y)/(freq.all$freq.x +
freq.all$freq.y +
2 * alpha)
#Sorting by NDSI
freq.all = freq.all[order(-freq.all$ndsi), ]
head(freq.all, 100)
#Convert word to a string
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
head(freq.all$word)
# Term Frequencies and tfidf with NDSI ----
#AFINN Frequency Function (now used with ndsi lexicon)
freq.all$word = as.character(freq.all$word)
library(stringr)
ndsi.frequencies=function(x){
str_count(x,freq.all$word[1:1024])
}
#Term Frequencies (Takes about two minutes to run)
term.freq <- t(apply(t(semisuper$clean), 2,
ndsi.frequencies))
inv.doc.freq=log(nrow(semisuper)/colSums(sign(term.freq)))
range(inv.doc.freq)
inv.doc.freq[is.infinite(inv.doc.freq)]=0
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
# Random Forest Using NDSI tf.idf ----
semisuper$polarity=as.factor(semisuper$polarity)
rf.semisuper=data.frame(polarity=semisuper$polarity,tf.idf)
#Random Forest (Takes about 15 min to run)
rf.model=randomForest(sentiment~.,data=rf.semisuper[train,])
rf.model=randomForest(polarity~.,data=rf.semisuper[train,])
View(train.data)
pred.polarity=predict(rf.model,
newdata=rf.movie.data[-train,])
pred.polarity=predict(rf.model,
newdata=rf.semisuper[-train,])
confusionMatrix(pred.polarity,movie.data$polarity[-train])
confusionMatrix(pred.polarity,semisuper$polarity[-train])
phat=predict(rf.model,
newdata=rf.movie.data[-train,],
type="prob")
phat=predict(rf.model,
newdata=rf.semisuper[-train,],
type="prob")
library(pROC)
plot(roc(movie.data$polarity[-train],phat[,2]))
library(pROC)
plot(roc(rf.semisuper$polarity[-train],phat[,2]))
happy = read.csv("happy_tweets.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[,c("text", "polarity")]),sad[,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
table(semisuper$polarity)
set.seed(945)
train = sample(1:nrow(semisuper), 0.7*nrow(semisuper))
train.data=semisuper[train,]
word.freq.pos = word.freq(train.data$clean[train.data$polarity == 1],
sparsity=0.999)
word.freq.neg = word.freq(train.data$clean[train.data$polarity == -1],
sparsity=0.999)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all = merge(word.freq.neg, word.freq.pos, by = 'word', all = T)
dim(word.freq.pos)
dim(word.freq.neg)
dim(freq.all)
word.freq.pos[1:20,]
word.freq.neg[1:20,]
freq.all[1:20,]
freq.all$freq.x[is.na(freq.all$freq.x)] = 0
freq.all$freq.y[is.na(freq.all$freq.y)] = 0
freq.all$diff = abs(freq.all$freq.x - freq.all$freq.y)
head(freq.all[order(-freq.all$diff), ])
alpha <- 2^7
freq.all$ndsi = abs(freq.all$freq.x -
freq.all$freq.y)/(freq.all$freq.x +
freq.all$freq.y +
2 * alpha)
freq.all = freq.all[order(-freq.all$ndsi), ]
head(freq.all, 100)
head(freq.all$word)
freq.all$word = as.character(freq.all$word)
head(freq.all$word)
# Term Frequencies and tfidf with NDSI ----
#AFINN Frequency Function (now used with ndsi lexicon)
freq.all$word = as.character(freq.all$word)
library(stringr)
ndsi.frequencies=function(x){
str_count(x,freq.all$word[1:1024])
}
term.freq <- t(apply(t(semisuper$clean), 2,
ndsi.frequencies))
inv.doc.freq=log(nrow(semisuper)/colSums(sign(term.freq)))
range(inv.doc.freq)
inv.doc.freq[is.infinite(inv.doc.freq)]=0
range(inv.doc.freq)
tf.idf = term.freq %*% diag(inv.doc.freq)
# Random Forest Using NDSI tf.idf ----
semisuper$polarity=as.factor(semisuper$polarity)
rf.semisuper=data.frame(polarity=semisuper$polarity,tf.idf)
View(rf.semisuper)
dim(rf.semisuper)
#Random Forest (Takes about 15 min to run)
rf.model=randomForest(polarity~.,data=rf.semisuper[train,])
#Classification Accuracy
pred.polarity=predict(rf.model,
newdata=rf.semisuper[-train,])
confusionMatrix(pred.polarity,semisuper$polarity[-train])
#ROC Curve
phat=predict(rf.model,
newdata=rf.semisuper[-train,],
type="prob")
library(pROC)
plot(roc(rf.semisuper$polarity[-train],phat[,2]))
happy = read.csv("happy_tweets2016.csv", stringsAsFactors = FALSE)
sad = read.csv("sad_tweets2016.csv", stringsAsFactors = FALSE)
happy$polarity = 1
sad$polarity = -1
semisuper = rbind(as.data.frame(happy[,c("text", "polarity")]),sad[,c("text", "polarity")])
semisuper$clean = clean.data(semisuper$text)
dim(semisuper)
